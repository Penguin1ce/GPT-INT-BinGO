# å…±äº«çŸ¥è¯†åº“ + ç§äººçŸ¥è¯†åº“è®¾è®¡æ–¹æ¡ˆ

## ğŸ“‹ ç›®å½•
1. [è®¾è®¡æ¦‚è¿°](#è®¾è®¡æ¦‚è¿°)
2. [æ•°æ®åº“è®¾è®¡](#æ•°æ®åº“è®¾è®¡)
3. [Redis é”®ç»“æ„](#redis-é”®ç»“æ„)
4. [ä»£ç å®ç°](#ä»£ç å®ç°)
5. [API è®¾è®¡](#api-è®¾è®¡)
6. [æ£€ç´¢ç­–ç•¥](#æ£€ç´¢ç­–ç•¥)
7. [è¿ç§»æ­¥éª¤](#è¿ç§»æ­¥éª¤)

---

## è®¾è®¡æ¦‚è¿°

### æ ¸å¿ƒæ¦‚å¿µ

**çŸ¥è¯†åº“ç±»å‹**ï¼š
- **SHAREDï¼ˆå…±äº«çŸ¥è¯†åº“ï¼‰**ï¼šæ‰€æœ‰ç”¨æˆ·å¯è¯»ï¼Œç®¡ç†å‘˜å¯ç®¡ç†
  - ç¤ºä¾‹ï¼šC++æ•™ç¨‹å®˜æ–¹æ–‡æ¡£ã€å¸¸è§é—®é¢˜åº“
  - è®¿é—®æ§åˆ¶ï¼šé»˜è®¤æ‰€æœ‰ç”¨æˆ·å¯è¯»

- **PRIVATEï¼ˆç§äººçŸ¥è¯†åº“ï¼‰**ï¼šç”¨æˆ·ä¸“å±ï¼Œä»…æ‰€æœ‰è€…å¯è®¿é—®
  - ç¤ºä¾‹ï¼šç”¨æˆ·ä¸ªäººç¬”è®°ã€å­¦ä¹ èµ„æ–™
  - è®¿é—®æ§åˆ¶ï¼šä»…æ‰€æœ‰è€…å’Œè¢«æˆæƒç”¨æˆ·

### æ¶æ„ä¼˜åŠ¿

âœ… **æ•°æ®éš”ç¦»**ï¼šä¸åŒçŸ¥è¯†åº“çš„å‘é‡æ•°æ®å®Œå…¨éš”ç¦»
âœ… **çµæ´»æƒé™**ï¼šæ”¯æŒå¤šçº§æƒé™æ§åˆ¶ï¼ˆADMIN/WRITER/READERï¼‰
âœ… **é«˜æ•ˆæ£€ç´¢**ï¼šæ”¯æŒè·¨çŸ¥è¯†åº“è”åˆæ£€ç´¢æˆ–å•åº“æ£€ç´¢
âœ… **å‘åå…¼å®¹**ï¼šå¯å¹³æ»‘è¿ç§»ç°æœ‰ç”¨æˆ·æ•°æ®

---

## æ•°æ®åº“è®¾è®¡

### 1. çŸ¥è¯†åº“è¡¨ (knowledge_bases)

```sql
CREATE TABLE IF NOT EXISTS knowledge_bases (
    id VARCHAR(64) PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    description TEXT,
    type VARCHAR(20) NOT NULL,  -- 'SHARED' æˆ– 'PRIVATE'
    owner_id VARCHAR(64),       -- SHAREDä¸ºNULLï¼ŒPRIVATEä¸ºç”¨æˆ·ID
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT fk_kb_owner FOREIGN KEY (owner_id)
        REFERENCES users(id) ON DELETE CASCADE,
    CONSTRAINT chk_kb_type CHECK (type IN ('SHARED', 'PRIVATE')),
    CONSTRAINT chk_kb_owner CHECK (
        (type = 'SHARED' AND owner_id IS NULL) OR
        (type = 'PRIVATE' AND owner_id IS NOT NULL)
    )
);

CREATE INDEX idx_kb_owner ON knowledge_bases(owner_id);
CREATE INDEX idx_kb_type ON knowledge_bases(type);
CREATE INDEX idx_kb_active ON knowledge_bases(is_active);
```

**å­—æ®µè¯´æ˜**ï¼š
- `type = SHARED` æ—¶ `owner_id` å¿…é¡»ä¸º NULL
- `type = PRIVATE` æ—¶ `owner_id` å¿…é¡»æŒ‡å‘ç”¨æˆ·
- `is_active` ç”¨äºè½¯åˆ é™¤

### 2. çŸ¥è¯†åº“è®¿é—®æƒé™è¡¨ (user_knowledge_base_access)

```sql
CREATE TABLE IF NOT EXISTS user_knowledge_base_access (
    id VARCHAR(64) PRIMARY KEY,
    user_id VARCHAR(64) NOT NULL,
    kb_id VARCHAR(64) NOT NULL,
    role VARCHAR(20) DEFAULT 'READER',  -- 'ADMIN', 'WRITER', 'READER'
    granted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    granted_by VARCHAR(64),  -- æˆæƒè€…ID

    CONSTRAINT fk_access_user FOREIGN KEY (user_id)
        REFERENCES users(id) ON DELETE CASCADE,
    CONSTRAINT fk_access_kb FOREIGN KEY (kb_id)
        REFERENCES knowledge_bases(id) ON DELETE CASCADE,
    CONSTRAINT chk_access_role CHECK (role IN ('ADMIN', 'WRITER', 'READER')),
    UNIQUE(user_id, kb_id)
);

CREATE INDEX idx_access_user ON user_knowledge_base_access(user_id);
CREATE INDEX idx_access_kb ON user_knowledge_base_access(kb_id);
```

**æƒé™è¯´æ˜**ï¼š
- **ADMIN**ï¼šå¯ç®¡ç†çŸ¥è¯†åº“ï¼ˆå¢åˆ æ–‡ä»¶ã€ä¿®æ”¹æƒé™ï¼‰
- **WRITER**ï¼šå¯ä¸Šä¼ æ–‡ä»¶åˆ°çŸ¥è¯†åº“
- **READER**ï¼šä»…å¯æ£€ç´¢çŸ¥è¯†åº“å†…å®¹

**ç‰¹æ®Šè§„åˆ™**ï¼š
- å…±äº«çŸ¥è¯†åº“ï¼šæ— æƒé™è®°å½• = æ‰€æœ‰ç”¨æˆ·é»˜è®¤ READER æƒé™
- ç§äººçŸ¥è¯†åº“ï¼šæ— æƒé™è®°å½• = æ— è®¿é—®æƒé™ï¼ˆé™¤æ‰€æœ‰è€…å¤–ï¼‰

### 3. ä¿®æ”¹ç°æœ‰è¡¨

```sql
-- uploaded_files æ·»åŠ çŸ¥è¯†åº“å…³è”
ALTER TABLE uploaded_files
    ADD COLUMN kb_id VARCHAR(64);

ALTER TABLE uploaded_files
    ADD CONSTRAINT fk_file_kb
        FOREIGN KEY (kb_id) REFERENCES knowledge_bases(id)
        ON DELETE CASCADE;

CREATE INDEX idx_files_kb ON uploaded_files(kb_id);

-- document_chunks æ·»åŠ çŸ¥è¯†åº“å…³è”ï¼ˆè™½ç„¶å½“å‰æœªä½¿ç”¨æ­¤è¡¨ï¼‰
ALTER TABLE document_chunks
    ADD COLUMN kb_id VARCHAR(64);
```

---

## Redis é”®ç»“æ„

### åŸæœ‰ç»“æ„ï¼ˆä»…æ”¯æŒæŒ‰ç”¨æˆ·éš”ç¦»ï¼‰
```
rag:user:{userId}:chunks          â†’ ZSet: ç”¨æˆ·çš„æ‰€æœ‰chunk ID
rag:file:{fileId}:chunks          â†’ Set: æ–‡ä»¶çš„chunk IDé›†åˆ
rag:chunk:{chunkId}               â†’ String: chunk JSONæ•°æ®
```

### æ–°ç»“æ„ï¼ˆæ”¯æŒçŸ¥è¯†åº“éš”ç¦»ï¼‰

```
# 1. çŸ¥è¯†åº“ç»´åº¦ç´¢å¼•
rag:kb:{kbId}:chunks              â†’ ZSet {chunkId => createdTimestamp}
                                    å­˜å‚¨æŸçŸ¥è¯†åº“çš„æ‰€æœ‰chunkï¼ŒæŒ‰æ—¶é—´æ’åº

# 2. ç”¨æˆ·è®¿é—®ç¼“å­˜
rag:user:{userId}:readable_kbs    â†’ Set {kbId1, kbId2, ...}
                                    ç”¨æˆ·å¯è¯»çš„çŸ¥è¯†åº“IDåˆ—è¡¨ï¼ˆå«ç§äºº+å…±äº«ï¼‰

# 3. æ–‡ä»¶å…³è”
rag:file:{fileId}:chunks          â†’ Set {chunkId1, chunkId2, ...}
                                    (ä¿æŒä¸å˜ï¼Œç”¨äºåˆ é™¤æ–‡ä»¶æ—¶æ¸…ç†)
rag:file:{fileId}:kb              â†’ String {kbId}
                                    æ–‡ä»¶æ‰€å±çŸ¥è¯†åº“ID

# 4. Chunkæ•°æ®
rag:chunk:{chunkId}               â†’ JSON {
                                      "id": "xxx",
                                      "userId": "xxx",
                                      "fileId": "xxx",
                                      "kbId": "xxx",        â† æ–°å¢å­—æ®µ
                                      "content": "...",
                                      "embeddingJson": "[...]",
                                      "createdAt": "..."
                                    }

# 5. çŸ¥è¯†åº“å…ƒæ•°æ®ç¼“å­˜ï¼ˆå¯é€‰ï¼ŒTTL=1å°æ—¶ï¼‰
rag:kb:{kbId}:meta                â†’ JSON {
                                      "id": "xxx",
                                      "name": "C++æ•™ç¨‹",
                                      "type": "SHARED",
                                      "ownerId": null
                                    }

# 6. å…±äº«çŸ¥è¯†åº“åˆ—è¡¨ç¼“å­˜ï¼ˆå¯é€‰ï¼ŒTTL=10åˆ†é’Ÿï¼‰
rag:shared_kbs                    â†’ Set {kbId1, kbId2, ...}
                                    æ‰€æœ‰æ´»è·ƒçš„å…±äº«çŸ¥è¯†åº“ID
```

### é”®è®¾è®¡åŸåˆ™

1. **æ•°æ®éš”ç¦»**ï¼šæ¯ä¸ªçŸ¥è¯†åº“çš„å‘é‡æ•°æ®å®Œå…¨ç‹¬ç«‹
2. **å¿«é€ŸæŸ¥è¯¢**ï¼šé€šè¿‡ç¼“å­˜å‡å°‘æ•°æ®åº“æŸ¥è¯¢
3. **æ‰¹é‡æ“ä½œ**ï¼šä½¿ç”¨ Pipeline ä¼˜åŒ–æ€§èƒ½
4. **çº§è”åˆ é™¤**ï¼šåˆ é™¤çŸ¥è¯†åº“æ—¶æ¸…ç†æ‰€æœ‰å…³è”æ•°æ®

---

## ä»£ç å®ç°

### 1. æ–°å¢ Entity ç±»

#### KnowledgeBase.java
```java
package com.firefly.ragdemo.entity;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import java.time.LocalDateTime;

@Data
@NoArgsConstructor
@AllArgsConstructor
@Builder
public class KnowledgeBase {
    private String id;
    private String name;
    private String description;
    private KnowledgeBaseType type;
    private String ownerId;  // PRIVATEç±»å‹æ—¶æœ‰å€¼
    private Boolean isActive;
    private LocalDateTime createdAt;
    private LocalDateTime updatedAt;
}
```

#### KnowledgeBaseType.java
```java
package com.firefly.ragdemo.entity;

public enum KnowledgeBaseType {
    SHARED,   // å…±äº«çŸ¥è¯†åº“
    PRIVATE   // ç§äººçŸ¥è¯†åº“
}
```

#### UserKnowledgeBaseAccess.java
```java
package com.firefly.ragdemo.entity;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import java.time.LocalDateTime;

@Data
@NoArgsConstructor
@AllArgsConstructor
@Builder
public class UserKnowledgeBaseAccess {
    private String id;
    private String userId;
    private String kbId;
    private AccessRole role;
    private LocalDateTime grantedAt;
    private String grantedBy;
}
```

#### AccessRole.java
```java
package com.firefly.ragdemo.entity;

public enum AccessRole {
    ADMIN,   // ç®¡ç†å‘˜
    WRITER,  // å†™å…¥è€…
    READER   // è¯»å–è€…
}
```

#### ä¿®æ”¹ DocumentChunk.java
```java
@Data
@NoArgsConstructor
@AllArgsConstructor
@Builder
public class DocumentChunk {
    private String id;
    private String userId;
    private String fileId;
    private String kbId;          // â† æ–°å¢å­—æ®µ
    private Integer chunkIndex;
    private String content;
    private String embeddingJson;
    private LocalDateTime createdAt;
}
```

### 2. Repository å±‚

#### RedisDocumentChunkRepository.java å…³é”®ä¿®æ”¹

```java
@Repository
@RequiredArgsConstructor
@Slf4j
public class RedisDocumentChunkRepository {

    private final StringRedisTemplate stringRedisTemplate;
    private final ObjectMapper objectMapper;

    private static final String KB_CHUNKS_PREFIX = "rag:kb:";
    private static final String USER_READABLE_KBS_PREFIX = "rag:user:";
    private static final String FILE_CHUNKS_PREFIX = "rag:file:";
    private static final String FILE_KB_PREFIX = "rag:file:";
    private static final String CHUNK_PREFIX = "rag:chunk:";

    /**
     * æ‰¹é‡ä¿å­˜chunksåˆ°æŒ‡å®šçŸ¥è¯†åº“
     */
    public void saveAll(List<DocumentChunk> chunks) {
        if (chunks == null || chunks.isEmpty()) {
            return;
        }

        stringRedisTemplate.executePipelined((RedisCallback<Object>) connection -> {
            for (DocumentChunk chunk : chunks) {
                if (chunk == null || chunk.getId() == null) continue;

                String serialized = serialize(chunk);
                byte[] chunkKeyBytes = chunkKey(chunk.getId()).getBytes();
                byte[] serializedBytes = serialized.getBytes();

                // 1. ä¿å­˜chunkå†…å®¹
                connection.set(chunkKeyBytes, serializedBytes);

                // 2. æ·»åŠ åˆ°çŸ¥è¯†åº“çš„ZSetï¼ˆæ–°é€»è¾‘ï¼‰
                if (chunk.getKbId() != null) {
                    double score = chunk.getCreatedAt() != null
                        ? chunk.getCreatedAt().toEpochSecond(ZoneOffset.UTC)
                        : System.currentTimeMillis() / 1000.0;
                    byte[] kbChunksKeyBytes = kbChunksKey(chunk.getKbId()).getBytes();
                    byte[] chunkIdBytes = chunk.getId().getBytes();
                    connection.zAdd(kbChunksKeyBytes, score, chunkIdBytes);
                }

                // 3. æ·»åŠ åˆ°æ–‡ä»¶çš„Set
                if (chunk.getFileId() != null) {
                    byte[] fileChunksKeyBytes = fileChunksKey(chunk.getFileId()).getBytes();
                    byte[] chunkIdBytes = chunk.getId().getBytes();
                    connection.sAdd(fileChunksKeyBytes, chunkIdBytes);

                    // è®°å½•æ–‡ä»¶æ‰€å±çŸ¥è¯†åº“
                    if (chunk.getKbId() != null) {
                        byte[] fileKbKeyBytes = fileKbKey(chunk.getFileId()).getBytes();
                        byte[] kbIdBytes = chunk.getKbId().getBytes();
                        connection.set(fileKbKeyBytes, kbIdBytes);
                    }
                }
            }
            return null;
        });

        log.debug("ä¿å­˜{}ä¸ªchunksåˆ°çŸ¥è¯†åº“", chunks.size());
    }

    /**
     * æ ¹æ®çŸ¥è¯†åº“IDåˆ—è¡¨æ£€ç´¢chunks
     * @param kbIds çŸ¥è¯†åº“IDåˆ—è¡¨
     * @param candidateLimit æ¯ä¸ªçŸ¥è¯†åº“çš„å€™é€‰æ•°é‡é™åˆ¶
     */
    public List<DocumentChunk> findByKnowledgeBases(List<String> kbIds, int candidateLimit) {
        if (kbIds == null || kbIds.isEmpty()) {
            return Collections.emptyList();
        }

        int limit = candidateLimit > 0 ? candidateLimit : 200;
        List<DocumentChunk> allChunks = new ArrayList<>();

        for (String kbId : kbIds) {
            // è·å–çŸ¥è¯†åº“çš„chunk IDs
            Set<String> chunkIds = stringRedisTemplate.opsForZSet()
                .reverseRange(kbChunksKey(kbId), 0, limit - 1);

            if (chunkIds == null || chunkIds.isEmpty()) {
                continue;
            }

            // æ‰¹é‡è·å–chunkå†…å®¹
            List<Object> results = stringRedisTemplate.executePipelined(
                (RedisCallback<Object>) connection -> {
                    for (String chunkId : chunkIds) {
                        connection.get(chunkKey(chunkId).getBytes());
                    }
                    return null;
                }
            );

            // ååºåˆ—åŒ–
            for (Object result : results) {
                if (result == null) continue;
                DocumentChunk chunk = deserialize(result.toString());
                if (chunk != null && kbId.equals(chunk.getKbId())) {
                    allChunks.add(chunk);
                }
            }
        }

        return allChunks;
    }

    /**
     * åˆ é™¤çŸ¥è¯†åº“çš„æ‰€æœ‰chunks
     */
    public void deleteByKnowledgeBase(String kbId) {
        if (kbId == null || kbId.isBlank()) {
            return;
        }

        // è·å–çŸ¥è¯†åº“çš„æ‰€æœ‰chunk IDs
        Set<String> chunkIds = stringRedisTemplate.opsForZSet()
            .range(kbChunksKey(kbId), 0, -1);

        if (chunkIds == null || chunkIds.isEmpty()) {
            return;
        }

        // æ‰¹é‡åˆ é™¤
        stringRedisTemplate.executePipelined((RedisCallback<Object>) connection -> {
            for (String chunkId : chunkIds) {
                connection.del(chunkKey(chunkId).getBytes());
            }
            // åˆ é™¤çŸ¥è¯†åº“ç´¢å¼•
            connection.del(kbChunksKey(kbId).getBytes());
            return null;
        });

        log.info("å·²åˆ é™¤çŸ¥è¯†åº“{}çš„{}ä¸ªchunks", kbId, chunkIds.size());
    }

    /**
     * åˆ é™¤æ–‡ä»¶çš„chunksï¼ˆéœ€è¦åŒæ—¶ä»çŸ¥è¯†åº“ç´¢å¼•ä¸­ç§»é™¤ï¼‰
     */
    public void deleteByFileIdAndKnowledgeBase(String fileId, String kbId) {
        Set<String> chunkIds = stringRedisTemplate.opsForSet()
            .members(fileChunksKey(fileId));

        if (chunkIds == null || chunkIds.isEmpty()) {
            return;
        }

        stringRedisTemplate.executePipelined((RedisCallback<Object>) connection -> {
            for (String chunkId : chunkIds) {
                // åˆ é™¤chunkå†…å®¹
                connection.del(chunkKey(chunkId).getBytes());

                // ä»çŸ¥è¯†åº“ZSetä¸­ç§»é™¤
                if (kbId != null) {
                    connection.zRem(
                        kbChunksKey(kbId).getBytes(),
                        chunkId.getBytes()
                    );
                }
            }
            // åˆ é™¤æ–‡ä»¶ç´¢å¼•
            connection.del(fileChunksKey(fileId).getBytes());
            connection.del(fileKbKey(fileId).getBytes());
            return null;
        });

        log.info("å·²åˆ é™¤æ–‡ä»¶{}çš„{}ä¸ªchunks", fileId, chunkIds.size());
    }

    // é”®ç”Ÿæˆæ–¹æ³•
    private String kbChunksKey(String kbId) {
        return KB_CHUNKS_PREFIX + kbId + ":chunks";
    }

    private String fileChunksKey(String fileId) {
        return FILE_CHUNKS_PREFIX + fileId + ":chunks";
    }

    private String fileKbKey(String fileId) {
        return FILE_KB_PREFIX + fileId + ":kb";
    }

    private String chunkKey(String chunkId) {
        return CHUNK_PREFIX + chunkId;
    }

    // åºåˆ—åŒ–æ–¹æ³•ï¼ˆçœç•¥ï¼Œä¸åŸä»£ç ç›¸åŒï¼‰
}
```

#### KnowledgeBaseMapper.javaï¼ˆMyBatisï¼‰

```java
package com.firefly.ragdemo.mapper;

import com.firefly.ragdemo.entity.KnowledgeBase;
import com.firefly.ragdemo.entity.UserKnowledgeBaseAccess;
import org.apache.ibatis.annotations.Mapper;
import org.apache.ibatis.annotations.Param;
import java.util.List;

@Mapper
public interface KnowledgeBaseMapper {

    // çŸ¥è¯†åº“CRUD
    void insertKnowledgeBase(KnowledgeBase kb);
    KnowledgeBase findById(String id);
    List<KnowledgeBase> findByOwnerId(String ownerId);
    List<KnowledgeBase> findAllShared();
    void updateKnowledgeBase(KnowledgeBase kb);
    void deleteById(String id);

    // æƒé™ç®¡ç†
    void grantAccess(UserKnowledgeBaseAccess access);
    void revokeAccess(@Param("userId") String userId, @Param("kbId") String kbId);
    UserKnowledgeBaseAccess findAccess(@Param("userId") String userId, @Param("kbId") String kbId);
    List<KnowledgeBase> findAccessibleKnowledgeBases(String userId);
}
```

### 3. Service å±‚

#### KnowledgeBaseService.java

```java
package com.firefly.ragdemo.service;

import com.firefly.ragdemo.entity.KnowledgeBase;
import com.firefly.ragdemo.entity.AccessRole;
import java.util.List;

public interface KnowledgeBaseService {

    // åˆ›å»ºçŸ¥è¯†åº“
    KnowledgeBase createSharedKnowledgeBase(String name, String description);
    KnowledgeBase createPrivateKnowledgeBase(String userId, String name, String description);

    // æŸ¥è¯¢çŸ¥è¯†åº“
    List<KnowledgeBase> getUserAccessibleKnowledgeBases(String userId);
    KnowledgeBase getKnowledgeBaseById(String kbId);

    // æƒé™ç®¡ç†
    void grantAccess(String kbId, String userId, AccessRole role, String grantedBy);
    void revokeAccess(String kbId, String userId);
    boolean checkAccess(String userId, String kbId, AccessRole minimumRole);

    // åˆ é™¤çŸ¥è¯†åº“
    void deleteKnowledgeBase(String kbId, String requestUserId);
}
```

#### RagRetrievalService.java ä¿®æ”¹

```java
public interface RagRetrievalService {

    /**
     * ä»æŒ‡å®šçŸ¥è¯†åº“æ£€ç´¢ä¸Šä¸‹æ–‡
     */
    List<String> retrieveContext(
        List<String> kbIds,  // æ”¯æŒå¤šçŸ¥è¯†åº“è”åˆæ£€ç´¢
        String query,
        int topK,
        int candidateLimit
    );

    /**
     * ä»ç”¨æˆ·å¯è®¿é—®çš„æ‰€æœ‰çŸ¥è¯†åº“æ£€ç´¢ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
     */
    List<String> retrieveContextForUser(
        String userId,
        String query,
        int topK,
        int candidateLimit
    );
}
```

### 4. Controller å±‚

#### KnowledgeBaseController.java

```java
package com.firefly.ragdemo.controller;

import com.firefly.ragdemo.dto.ApiResponse;
import com.firefly.ragdemo.dto.CreateKnowledgeBaseRequest;
import com.firefly.ragdemo.entity.KnowledgeBase;
import com.firefly.ragdemo.service.KnowledgeBaseService;
import lombok.RequiredArgsConstructor;
import org.springframework.security.core.annotation.AuthenticationPrincipal;
import org.springframework.security.core.userdetails.UserDetails;
import org.springframework.web.bind.annotation.*;

import java.util.List;

@RestController
@RequestMapping("/api/knowledge-bases")
@RequiredArgsConstructor
public class KnowledgeBaseController {

    private final KnowledgeBaseService knowledgeBaseService;

    /**
     * åˆ›å»ºç§äººçŸ¥è¯†åº“
     */
    @PostMapping("/private")
    public ApiResponse<KnowledgeBase> createPrivateKnowledgeBase(
        @AuthenticationPrincipal UserDetails userDetails,
        @RequestBody CreateKnowledgeBaseRequest request
    ) {
        String userId = userDetails.getUsername();
        KnowledgeBase kb = knowledgeBaseService.createPrivateKnowledgeBase(
            userId, request.getName(), request.getDescription()
        );
        return ApiResponse.success(kb);
    }

    /**
     * åˆ›å»ºå…±äº«çŸ¥è¯†åº“ï¼ˆéœ€è¦ç®¡ç†å‘˜æƒé™ï¼‰
     */
    @PostMapping("/shared")
    public ApiResponse<KnowledgeBase> createSharedKnowledgeBase(
        @RequestBody CreateKnowledgeBaseRequest request
    ) {
        KnowledgeBase kb = knowledgeBaseService.createSharedKnowledgeBase(
            request.getName(), request.getDescription()
        );
        return ApiResponse.success(kb);
    }

    /**
     * è·å–å½“å‰ç”¨æˆ·å¯è®¿é—®çš„çŸ¥è¯†åº“åˆ—è¡¨
     */
    @GetMapping
    public ApiResponse<List<KnowledgeBase>> getAccessibleKnowledgeBases(
        @AuthenticationPrincipal UserDetails userDetails
    ) {
        String userId = userDetails.getUsername();
        List<KnowledgeBase> kbs = knowledgeBaseService
            .getUserAccessibleKnowledgeBases(userId);
        return ApiResponse.success(kbs);
    }

    /**
     * æˆäºˆç”¨æˆ·è®¿é—®æƒé™ï¼ˆéœ€è¦ADMINæƒé™ï¼‰
     */
    @PostMapping("/{kbId}/access")
    public ApiResponse<Void> grantAccess(
        @PathVariable String kbId,
        @RequestParam String targetUserId,
        @RequestParam String role,
        @AuthenticationPrincipal UserDetails userDetails
    ) {
        String grantedBy = userDetails.getUsername();
        knowledgeBaseService.grantAccess(
            kbId, targetUserId, AccessRole.valueOf(role), grantedBy
        );
        return ApiResponse.success(null);
    }

    /**
     * åˆ é™¤çŸ¥è¯†åº“
     */
    @DeleteMapping("/{kbId}")
    public ApiResponse<Void> deleteKnowledgeBase(
        @PathVariable String kbId,
        @AuthenticationPrincipal UserDetails userDetails
    ) {
        String userId = userDetails.getUsername();
        knowledgeBaseService.deleteKnowledgeBase(kbId, userId);
        return ApiResponse.success(null);
    }
}
```

---

## API è®¾è®¡

### æ–°å¢ REST æ¥å£

```
# çŸ¥è¯†åº“ç®¡ç†
POST   /api/knowledge-bases/private        åˆ›å»ºç§äººçŸ¥è¯†åº“
POST   /api/knowledge-bases/shared         åˆ›å»ºå…±äº«çŸ¥è¯†åº“ï¼ˆç®¡ç†å‘˜ï¼‰
GET    /api/knowledge-bases                è·å–å¯è®¿é—®çš„çŸ¥è¯†åº“åˆ—è¡¨
GET    /api/knowledge-bases/{kbId}         è·å–çŸ¥è¯†åº“è¯¦æƒ…
DELETE /api/knowledge-bases/{kbId}         åˆ é™¤çŸ¥è¯†åº“

# æƒé™ç®¡ç†
POST   /api/knowledge-bases/{kbId}/access  æˆäºˆè®¿é—®æƒé™
DELETE /api/knowledge-bases/{kbId}/access/{userId}  æ’¤é”€è®¿é—®æƒé™

# æ–‡ä»¶ä¸Šä¼ ï¼ˆä¿®æ”¹ï¼‰
POST   /api/files/upload?kbId={kbId}       ä¸Šä¼ æ–‡ä»¶åˆ°æŒ‡å®šçŸ¥è¯†åº“

# èŠå¤©ï¼ˆä¿®æ”¹ï¼‰
POST   /api/chat?kbIds=kb1,kb2,kb3          æ”¯æŒæŒ‡å®šçŸ¥è¯†åº“åˆ—è¡¨æ£€ç´¢
```

### è¯·æ±‚/å“åº”ç¤ºä¾‹

#### åˆ›å»ºç§äººçŸ¥è¯†åº“
```json
POST /api/knowledge-bases/private
{
  "name": "æˆ‘çš„å­¦ä¹ ç¬”è®°",
  "description": "ä¸ªäººC++å­¦ä¹ èµ„æ–™"
}

Response:
{
  "success": true,
  "data": {
    "id": "kb_xxx",
    "name": "æˆ‘çš„å­¦ä¹ ç¬”è®°",
    "type": "PRIVATE",
    "ownerId": "user_123",
    "createdAt": "2025-01-10T10:00:00"
  }
}
```

#### è·å–å¯è®¿é—®çš„çŸ¥è¯†åº“åˆ—è¡¨
```json
GET /api/knowledge-bases

Response:
{
  "success": true,
  "data": [
    {
      "id": "kb_shared_1",
      "name": "C++å®˜æ–¹æ•™ç¨‹",
      "type": "SHARED",
      "ownerId": null
    },
    {
      "id": "kb_private_user123",
      "name": "æˆ‘çš„å­¦ä¹ ç¬”è®°",
      "type": "PRIVATE",
      "ownerId": "user_123"
    }
  ]
}
```

---

## æ£€ç´¢ç­–ç•¥

### 1. å¤šçŸ¥è¯†åº“è”åˆæ£€ç´¢

```java
public List<String> retrieveContext(List<String> kbIds, String query, int topK) {
    // 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
    List<Double> queryEmbedding = embeddingService.embed(query);

    // 2. ä»å¤šä¸ªçŸ¥è¯†åº“è·å–å€™é€‰chunks
    List<DocumentChunk> candidates = redisRepository
        .findByKnowledgeBases(kbIds, topK * 4);

    // 3. è®¡ç®—ç›¸ä¼¼åº¦å¹¶æ’åº
    List<ScoredChunk> scored = candidates.stream()
        .map(chunk -> new ScoredChunk(
            chunk.getContent(),
            cosineSimilarity(queryEmbedding, chunk.getEmbeddingJson())
        ))
        .sorted(Comparator.comparing(ScoredChunk::score).reversed())
        .limit(topK)
        .toList();

    return scored.stream()
        .map(ScoredChunk::content)
        .toList();
}
```

### 2. æ£€ç´¢ä¼˜å…ˆçº§ç­–ç•¥

**æ–¹æ¡ˆAï¼šå¹³ç­‰æ£€ç´¢**
- ä»æ¯ä¸ªçŸ¥è¯†åº“å–ç›¸åŒæ•°é‡çš„å€™é€‰chunks
- ä¼˜ç‚¹ï¼šä¿è¯å„çŸ¥è¯†åº“éƒ½æœ‰ä»£è¡¨
- é€‚ç”¨åœºæ™¯ï¼šå…±äº«åº“+ç§äººåº“è”åˆæ£€ç´¢

**æ–¹æ¡ˆBï¼šåŠ æƒæ£€ç´¢**
- ç§äººçŸ¥è¯†åº“æƒé‡æ›´é«˜ï¼ˆä¾‹å¦‚2:1ï¼‰
- ä¼˜ç‚¹ï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·ä¸“å±æ•°æ®
- é€‚ç”¨åœºæ™¯ï¼šä¸ªæ€§åŒ–å­¦ä¹ åŠ©æ‰‹

**æ–¹æ¡ˆCï¼šåŠ¨æ€ç­–ç•¥**
- æ ¹æ®æŸ¥è¯¢æ„å›¾æ™ºèƒ½é€‰æ‹©çŸ¥è¯†åº“
- ä¼˜ç‚¹ï¼šæ›´ç²¾å‡†çš„ç»“æœ
- å®ç°ï¼šé€šè¿‡æŸ¥è¯¢åˆ†ç±»æˆ–ç”¨æˆ·é…ç½®

### 3. å®ç°ç¤ºä¾‹ï¼ˆå¹³ç­‰æ£€ç´¢ï¼‰

```java
public List<DocumentChunk> findByKnowledgeBases(List<String> kbIds, int candidateLimit) {
    int perKbLimit = candidateLimit / kbIds.size();  // å¹³å‡åˆ†é…

    List<DocumentChunk> allChunks = new ArrayList<>();
    for (String kbId : kbIds) {
        Set<String> chunkIds = stringRedisTemplate.opsForZSet()
            .reverseRange(kbChunksKey(kbId), 0, perKbLimit - 1);

        // ... æ‰¹é‡è·å–chunkå†…å®¹
        allChunks.addAll(fetchedChunks);
    }
    return allChunks;
}
```

---

## è¿ç§»æ­¥éª¤

### é˜¶æ®µä¸€ï¼šæ•°æ®åº“å‡†å¤‡

```bash
# 1. æ‰§è¡Œæ•°æ®åº“è¿ç§»SQLï¼ˆMySQL 8+ï¼‰
mysql -h 127.0.0.1 -P 3306 -u ragdemo -p ragdemo < migration_knowledge_bases.sql

# 2. åˆ›å»ºé»˜è®¤å…±äº«çŸ¥è¯†åº“ï¼ˆå¦‚éœ€è¦é¢å¤–ç¤ºä¾‹æ•°æ®ï¼‰
INSERT INTO knowledge_bases (id, name, description, type, owner_id, is_active)
VALUES ('kb_shared_default', 'C++æ•™å­¦å®˜æ–¹çŸ¥è¯†åº“', 'é‡åº†å¤§å­¦C++è¯¾ç¨‹å®˜æ–¹èµ„æ–™', 'SHARED', NULL, TRUE);
```

### é˜¶æ®µäºŒï¼šè¿ç§»ç°æœ‰æ•°æ®

```java
// ä¸ºæ‰€æœ‰ç°æœ‰ç”¨æˆ·åˆ›å»ºé»˜è®¤ç§äººçŸ¥è¯†åº“
public void migrateExistingUsers() {
    List<User> users = userMapper.findAll();

    for (User user : users) {
        // 1. åˆ›å»ºç§äººçŸ¥è¯†åº“
        KnowledgeBase kb = KnowledgeBase.builder()
            .id("kb_private_" + user.getId())
            .name(user.getUsername() + "çš„çŸ¥è¯†åº“")
            .type(KnowledgeBaseType.PRIVATE)
            .ownerId(user.getId())
            .isActive(true)
            .build();
        kbMapper.insertKnowledgeBase(kb);

        // 2. å°†ç”¨æˆ·ç°æœ‰æ–‡ä»¶å…³è”åˆ°æ–°çŸ¥è¯†åº“
        fileMapper.updateKnowledgeBaseByUserId(user.getId(), kb.getId());

        // 3. æ›´æ–°Redisä¸­çš„chunkæ•°æ®
        List<DocumentChunk> chunks = redisRepository.findByUser(user.getId(), 10000);
        for (DocumentChunk chunk : chunks) {
            chunk.setKbId(kb.getId());
        }
        redisRepository.saveAll(chunks);  // é‡æ–°ä¿å­˜ä»¥æ›´æ–°kbId
    }
}
```

### é˜¶æ®µä¸‰ï¼šä»£ç éƒ¨ç½²

1. éƒ¨ç½²æ–°ä»£ç ï¼ˆåŒ…å«å‘åå…¼å®¹é€»è¾‘ï¼‰
2. éªŒè¯ç°æœ‰åŠŸèƒ½æ­£å¸¸
3. é€æ­¥åˆ‡æ¢åˆ°æ–°API

### é˜¶æ®µå››ï¼šå‰ç«¯é€‚é…

1. åœ¨æ–‡ä»¶ä¸Šä¼ ç•Œé¢æ·»åŠ çŸ¥è¯†åº“é€‰æ‹©å™¨
2. åœ¨èŠå¤©ç•Œé¢æ”¯æŒçŸ¥è¯†åº“ç­›é€‰
3. æ·»åŠ çŸ¥è¯†åº“ç®¡ç†é¡µé¢

---

## æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿

âœ… **æ•°æ®éš”ç¦»æ¸…æ™°**ï¼šå…±äº«/ç§äººçŸ¥è¯†åº“å®Œå…¨ç‹¬ç«‹
âœ… **æƒé™æ§åˆ¶çµæ´»**ï¼šæ”¯æŒç»†ç²’åº¦è®¿é—®æ§åˆ¶
âœ… **æ£€ç´¢æ€§èƒ½é«˜æ•ˆ**ï¼šåŸºäºRedis ZSetå®ç°O(log N)æŸ¥è¯¢
âœ… **æ‰©å±•æ€§å¼º**ï¼šå¯è½»æ¾æ·»åŠ ç»„ç»‡çº§çŸ¥è¯†åº“ã€å›¢é˜ŸçŸ¥è¯†åº“ç­‰

### ä¸‹ä¸€æ­¥å»ºè®®

1. **å®ç°çŸ¥è¯†åº“ç»Ÿè®¡**ï¼šæ–‡ä»¶æ•°ã€chunkæ•°ã€æœ€åæ›´æ–°æ—¶é—´
2. **æ·»åŠ çŸ¥è¯†åº“æ ‡ç­¾**ï¼šæ”¯æŒæŒ‰å­¦ç§‘ã€è¯¾ç¨‹åˆ†ç±»
3. **å®ç°çŸ¥è¯†åº“å¯¼å‡º**ï¼šæ”¯æŒå¤‡ä»½å’Œè¿ç§»
4. **å¢å¼ºæƒé™ç³»ç»Ÿ**ï¼šæ”¯æŒè§’è‰²ç»§æ‰¿ã€ä¸´æ—¶æˆæƒç­‰
5. **ç›‘æ§å’Œå‘Šè­¦**ï¼šçŸ¥è¯†åº“ä½¿ç”¨ç»Ÿè®¡ã€å¼‚å¸¸æ£€æµ‹

### æŠ€æœ¯å€ºåŠ¡

- å½“å‰ `document_chunks` MySQL è¡¨æœªä½¿ç”¨ï¼Œå¯è€ƒè™‘åˆ é™¤
- Redis ç¼“å­˜è¿‡æœŸç­–ç•¥éœ€ç»†åŒ–ï¼ˆé¿å…å†…å­˜æ³„æ¼ï¼‰
- å¤§è§„æ¨¡çŸ¥è¯†åº“ï¼ˆ>10ä¸‡chunksï¼‰éœ€è€ƒè™‘åˆ†ç‰‡ç­–ç•¥
